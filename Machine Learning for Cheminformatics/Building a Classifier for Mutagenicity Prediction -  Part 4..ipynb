{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Part 4. Testing the classifiers on a bigger data set."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this part we will test our predictive models on a larger dataset (7090 compounds). For more detailed explanation of the code below, see the previous parts ([Part 1](http://nbviewer.ipython.org/gist/py-chemist/12390b995cfbb1c0f6ac), [Part 2](http://nbviewer.ipython.org/gist/py-chemist/3ccad77d6e808e3742d2), [Part 3](http://nbviewer.ipython.org/gist/py-chemist/117ddfabd43ae013d918))."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random\n",
      "import csv\n",
      "\n",
      "def split_data():\n",
      "    '''\n",
      "    Split data into a training and a testing set.\n",
      "    '''\n",
      "    with open('/home/py-chemist/Projects/Machine_Learning/Mutagenes/7090_mutagens.csv', 'rb') as f:\n",
      "        csv_reader = csv.reader(f, delimiter = ',')\n",
      "        header = csv_reader.next()\n",
      "        data = [row for row in csv_reader]\n",
      "        train_data = random.sample(data, 5000)\n",
      "        test_data = [i for i in data if i not in train_data]\n",
      "    return header, train_data, test_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def write_to_csv(file_name, header, data):\n",
      "    \"\"\"\n",
      "    Write data to a .csv file\n",
      "    \"\"\"\n",
      "    with open(file_name, 'wb') as f:\n",
      "        csv_writer = csv.writer(f, delimiter=',')\n",
      "        csv_writer.writerow(header)\n",
      "        csv_writer.writerows(data)\n",
      "        \n",
      "header, train_data, test_data = split_data()\n",
      "write_to_csv('7090_train_data.csv', header, train_data)\n",
      "write_to_csv('7090_test_data.csv', header, test_data)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Downloads: [7090_train_data.csv](https://www.dropbox.com/s/6o1xfxi2qtjxv0m/7090_train_data.csv?dl=0), [7090_test_data.csv](https://www.dropbox.com/s/or8h4b38len6h1x/7090_test_data.csv?dl=0)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_train = pd.read_csv('7090_train_data.csv').dropna().drop('ExactMolWt', axis = 1)\n",
      "\n",
      "df_test = pd.read_csv('7090_test_data.csv').dropna().drop('ExactMolWt', axis = 1)\n",
      "\n",
      "X_train = df_train[df_train.columns[:-2]]\n",
      "y_train = df_train.labels\n",
      "\n",
      "X_test = df_test[df_test.columns[:-2]]\n",
      "y_test = df_test.labels\n",
      "                   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "std_scale = StandardScaler().fit(X_train)\n",
      "X_train_std = std_scale.transform(X_train)\n",
      "X_test_std = std_scale.transform(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import  metrics\n",
      "import pickle\n",
      "\n",
      "# Loading the model preserved in part two\n",
      "with open('/home/py-chemist/Projects/Machine_Learning/Mutagenes/mutagen_model.pickle', 'rb') as f:\n",
      "    random_forest = pickle.load(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "rf = RandomForestClassifier(n_estimators = 40)\n",
      "\n",
      "rf.fit(X_train_std, y_train)\n",
      "\n",
      "rf_pred = rf.predict(X_test_std)\n",
      "\n",
      "score = metrics.accuracy_score(y_test,rf_pred)\n",
      "print score\n",
      "conf_matrix = metrics.confusion_matrix(y_test, rf_pred)\n",
      "print conf_matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.829420220412\n",
        "[[836 171]\n",
        " [185 895]]\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "\n",
      "def spec_sens(matrix):\n",
      "    print \"Specificity:\", matrix[1,1]/sum(matrix[1, :])\n",
      "    print \"Sensitivity:\", matrix[0,0]/sum(matrix[0,:])\n",
      "    \n",
      "spec_sens(conf_matrix)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Specificity: 0.828703703704\n",
        "Sensitivity: 0.830188679245\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_toxi = ['a[N;X2]=O', 'CO[N;X2]=O', 'N[N;X2]=O', 'O1[c,C]-[c,C]1', 'C1NC1',\n",
      "     'N=[N+]=[N-]', 'C=[N+]=[N-]','N=N-N', 'cN!@;=[N;X3]', '[OH]O', '[OH][N;X2]=C',\n",
      "    '[c,C]OO[c,C]', 'C[NH][NH]C', '[OH]Na', '[NH2]Na', '[OH][N;X2]=[N;X2]',\n",
      "    '[Cl,Br,I]C', '[Cl,Br,I]C=O', '[N,S]!@[C;X4]!@[CH2][Cl,Br,I]', 'SC[Cl]',\n",
      "    '[Cl,Br,I]!@[C;X4]!@[C;X4]O', '[Cl]C([X1])=C[X1]','[Cl,Br,I]C(([F,Cl,Br,I])[X1])C=C',\n",
      "    '[cH]1[cH]ccc2c1c3c(cc2)cc[cH][cH]3','[Cl,Br,I]C(([F,Cl,Br,I])[X1])C(=O)[c,C]',\n",
      "    '[cH]1ccc2c1[cH][cH]c3c2ccc[cH]3', '[C,c]OS((=O)=O)O!@[c,C]','[c,C]S((=O)=O!@[c,C])',\n",
      "    'O=N(~O)N', '[N;v4]#N', 'O=C1CCO1', '[CH]=[CH]O','aN([OH])','aN(O*=O)', 'aN([#1])',\n",
      "    'aN(C=O)[CH3]', 'aN[CH3]',\n",
      "    '[NH;!R][NH;!R]a', '[CH3][NH]a', 'a13~a~a~a~a2~a1~a(~a~a~a~3)~a~a~a~2',\n",
      "    'a1~a~a~a2~a~1~a~a3~a(~a~2)~a~a~a~3', 'a1~a~a~a2~a~1~a~a~a3~a~2~a~a~a~3',\n",
      "    'a1~a~a~a~2a~a~1~a3~a(~a~2)~a~a~a~a~3','a1~a~a~a~2a~a~1~a~a3~a(~a~2)~a~a~a~3',\n",
      "    'a1~a~a~a~2a~a~1~a~a3~a(~a~2)~a~a~a~a~3', 'a1~a~a~a~2a~a~1~a~a~a3~a~2~a~a~a~3',\n",
      "    'a1~a~a~a~2a~a~1~a~a~a3~a~2~a~a~a~a~3', 'a13~a~a~a~2a~a1~a(~a~a~a~3)~a~a~2']\n",
      "\n",
      "\n",
      "\n",
      "d = {'O=N(~O)a':['O=N(O)c(aS(=O)=O)', 'O=N(O)c(aaS(=O)=O)','O=N(O)c(aaaS(=O)=O)',\n",
      "                 'O=N(O)c(aC((F)F)F)', 'O=N(O)c(aaC((F)F)F)', 'O=N(O)c(aaaC((F)F)F)'],\n",
      "     'a[NH2]':['[NH2]a(a(C((F)F)F))', '[NH2]a(a(S(=O)=O))', '[NH2]a(a(C(=O)O))',\n",
      "               '[NH2]a(aa(C((F)F)F))', '[NH2]a(aa(S(=O)=O))' '[NH2]a(aa(C(=O)O))',\n",
      "               '[NH2]a(aaa(C((F)F)F))', '[NH2]a(aaa(S(=O)=O))', '[NH2]a(aaa(C(=O)O))'],\n",
      "     'c[N;X2]!@;=[N;X2]c':['[N;X2](acS((=O)=O))=[N;X2](acS((=O)=O))','[N;X2](aacS((=O)=O))=[N;X2](aacS((=O)=O))',\n",
      "                           '[N;X2](aaacS((=O)=O))=[N;X2](aaacS((=O)=O))','[N;X2](aaaacS((=O)=O))=[N;X2](aaaacS((=O)=O))'],\n",
      "     '[OH,NN2][N,O]': ['O=N(O)[O-]'],\n",
      "     '[OH]N':['[OH]Na','[OH][N;X2]=*'],\n",
      "     '[Cl,Br,I][C;X4]': ['[Cl,Br,I][C;X4][F,Cl,Br,I]','[Cl,Br,I]C((C)C)C'],\n",
      "     '[Cl,Br,I][CH][CH3]':['[Cl,Br,I][C]([Cl,Br,I,F])[CH3]'],\n",
      "     'O=[CH]C=C':['O=[CH]C([N,O,S])=C','O=[CH]C=C[N,O,S]','O=[CH]C=Ca'],\n",
      "     'O=[CH]C=O':['O=[CH]C([N,O,S])=C','O=[CH]C=C[N,O,S]','O=[CH]C=Ca'],\n",
      "     '[CH3][NH]a':['[CH3][NH]a(a(C((F)F)F))', '[CH3][NH]a(a(S=O))','[CH3][NH]a(a(C(=O)O))',\n",
      "                   '[CH3][NH]a(aa(C((F)F)F))','[CH3][NH]a(aa(S=O))','[CH3][NH]a(aa(C(=O)O))',\n",
      "                   '[CH3][NH]a(aaa(C((F)F)F))','[CH3][NH]a(aaa(S=O))', '[CH3][NH]a(aaa(C(=O)O))']\n",
      "     }"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pybel as pb\n",
      "\n",
      "all_smiles = df_test.smiles\n",
      "\n",
      "def unique_toxi():\n",
      "    mol_list = []\n",
      "    for smiles in all_smiles: \n",
      "        l = []\n",
      "        mol = pb.readstring(\"smi\",smiles) \n",
      "        for toxi in all_toxi:            \n",
      "            smarts = pb.Smarts(toxi)\n",
      "            if len(smarts.findall(mol)) > 0:\n",
      "                l.append(1)\n",
      "            else:\n",
      "                l.append(0)\n",
      "        mol_list.append(sum(l))\n",
      "        \n",
      "    return mol_list\n",
      "\n",
      "def dict_toxi():\n",
      "    mol_list = []\n",
      "    for smiles in all_smiles:\n",
      "        l = []\n",
      "        mol = pb.readstring(\"smi\",smiles)\n",
      "        for k,v in d.iteritems():            \n",
      "            k_smarts = pb.Smarts(k)\n",
      "            n = len(k_smarts.findall(mol))\n",
      "            if n == 0:\n",
      "                l.append(0)\n",
      "            else:                \n",
      "                for each in v:\n",
      "                    d_list = []\n",
      "                    v_smarts = pb.Smarts(each)\n",
      "                    d_list.append(len(v_smarts.findall(mol)))\n",
      "                    if n > sum(d_list):\n",
      "                        l.append(1)\n",
      "                    elif n == sum(d_list):\n",
      "                        l.append(0) \n",
      "        mol_list.append(sum(l))\n",
      "                    \n",
      "    return mol_list                   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_toxi_labels =  np.array(unique_toxi()) + np.array(dict_toxi())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "merged_toxi = []\n",
      "\n",
      "for i in all_toxi_labels:\n",
      "    if i == 0:\n",
      "        merged_toxi.append(0)\n",
      "    else:\n",
      "        merged_toxi.append(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "score = metrics.accuracy_score(y_test,merged_toxi)\n",
      "print score\n",
      "conf_m =  metrics.confusion_matrix(y_test, merged_toxi)\n",
      "print conf_m\n",
      "spec_sens(conf_m)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.723047436512\n",
        "[[748 259]\n",
        " [319 761]]\n",
        "Specificity: 0.70462962963\n",
        "Sensitivity: 0.742800397219\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Vote for the specificity."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vote_for_spec = []\n",
      "\n",
      "for i in range(len(merged_toxi)):\n",
      "    if rf_pred[i] == 1:\n",
      "        vote_for_spec.append(1)\n",
      "    else:\n",
      "        vote_for_spec.append(merged_toxi[i])        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "score = metrics.accuracy_score(y_test, vote_for_spec)\n",
      "print score\n",
      "print '\\n',metrics.confusion_matrix(y_test, vote_for_spec)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.789171058936\n",
        "\n",
        "[[668 339]\n",
        " [101 979]]\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "\n",
      "def spec_sens(matrix):\n",
      "    print \"Specificity:\", matrix[1,1]/sum(matrix[1, :])\n",
      "    print \"Sensitivity:\", matrix[0,0]/sum(matrix[0,:])\n",
      "    \n",
      "spec_sens(metrics.confusion_matrix(y_test, vote_for_spec))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Specificity: 0.906481481481\n",
        "Sensitivity: 0.663356504469\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Vote for sensitivity."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vote_for_sens = []\n",
      "\n",
      "for i in range(len(merged_toxi)):\n",
      "    if merged_toxi[i] == 0:\n",
      "        vote_for_sens.append(0)\n",
      "    else:\n",
      "        vote_for_sens.append(rf_pred[i])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "score = metrics.accuracy_score(y_test, vote_for_sens)\n",
      "print score\n",
      "print '\\n',metrics.confusion_matrix(y_test, vote_for_sens)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.763296597988\n",
        "\n",
        "[[916  91]\n",
        " [403 677]]\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "def spec_sens(matrix):\n",
      "    print \"Specificity:\", matrix[1,1]/sum(matrix[1, :])\n",
      "    print \"Sensitivity:\", matrix[0,0]/sum(matrix[0,:])\n",
      "    \n",
      "spec_sens(metrics.confusion_matrix(y_test, vote_for_sens))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Specificity: 0.626851851852\n",
        "Sensitivity: 0.909632571996\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "   ### A summary table"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "                    |          |  Vote_for_Spesificity  | Vote_for_Sensitivity |\n",
      "                    |----------------------------------------------------------|\n",
      "                    |  4335    |       0.92             |       0.91           |\n",
      "                    |  7090    |       0.91             |       0.91           |"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The summary table shows that the Voting algorithm works equally well for smaller and bigger data sets."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}